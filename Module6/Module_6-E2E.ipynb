{"cells":[{"cell_type":"markdown","source":["# MOdule 6 - E2E\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"46381158-c665-4864-98f6-feaeae6d69b2"},{"cell_type":"markdown","source":["### To create an end-to-end machine learning solution in Microsoft Fabric using PySpark\n"," we can follow a structured workflow that includes:\n","\n","* Data Preparation: Loading data from both a Lakehouse and Data Lake, and merging them.\n","* Exploratory Data Analysis (EDA): Understanding the dataset through visualization and descriptive statistics.\n","* Feature Engineering: Preprocessing the data to prepare it for machine learning.\n","* Model Building: Training a prediction model.\n","* Model Evaluation: Testing the model on unseen data.\n","* API or Inference: Implementing a simple method for inference to make predictions using the trained model."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"eaa9bdd6-b8ab-431c-aa32-d360c66014f1"},{"cell_type":"markdown","source":["## Fabric Prerequistis\n","\n","You need to have Lakehouse enabled and connected. \n","\n","Link to Lakehouse:\n","- Tables: `abfss://Fabric_2024@onelake.dfs.fabric.microsoft.com/LK_flights.Lakehouse/Tables`\n","- Files: `abfss://Fabric_2024@onelake.dfs.fabric.microsoft.com/LK_flights.Lakehouse/Files`\n","\n","You will also need:\n","- link to https://www.kaggle.com/datasets/camnugent/california-housing-prices\n","- PySpark notebook and connect it to the Fabric standard session\n","- data for inference"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c2ac77e9-4795-4f3c-803d-3f1b2776fe6e"},{"cell_type":"markdown","source":["## Dataset: California Housing Prices\n","\n","- Dataset Source: Available from the California Housing Prices dataset on Kaggle.\n","- File Format: CSV (or you can download it through sklearn.datasets in Python).\n","- Target Variable: **median_house_value**\n","- Features: Includes _median_income_, _house_age_, _total_rooms_, _population_, etc."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fe3722b3-5df3-4be1-bc40-7bf92f63396e"},{"cell_type":"markdown","source":["In addition, save this set of values for inference data:\n","\n","```\n","longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,households,median_income\n","-122.23,37.88,41,880,129,322,126,8.3252\n","-122.22,37.86,21,7099,1106,2401,1138,8.3014\n","-122.24,37.85,52,1467,190,496,177,7.2574\n","-122.25,37.85,52,1274,235,558,219,5.6431\n","-122.25,37.85,52,1627,280,565,259,3.8462\n","```\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"24b43513-baaa-4084-a978-2d060cc521af"},{"cell_type":"markdown","source":["## Step 1: Data preparation"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d1b255a9-620f-4711-a2b3-15d408384da8"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"CaliforniaHousingML\").getOrCreate()\n","\n","# Load historical data from Lakehouse\n","lakehouse_data_path = \"Files/Users/Lakehouse/CaliforniaHousing.csv\"\n","df_lakehouse = spark.read.csv(lakehouse_data_path, header=True, inferSchema=True)\n","\n","# Load additional data from Data Lake\n","data_lake_path = \"Files/Users/DataLake/NewCaliforniaHousing.csv\"\n","df_datalake = spark.read.csv(data_lake_path, header=True, inferSchema=True)\n","\n","df_lakehouse.printSchema()\n","df_datalake.printSchema()\n","\n","# Merge the datasets \n","df = df_lakehouse.unionByName(df_datalake)\n","\n","df.show(5)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cb9e4e92-5d91-4596-967d-2d9823d9b40d"},{"cell_type":"markdown","source":["## Step 2: Exploratory Data Analysis (EDA)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"29ebd6d1-f643-4bb2-918b-fede1f56f56b"},{"cell_type":"markdown","source":["Perform Exploratory Data Analysis to understand key characteristics of the dataset. This includes viewing the distribution of key features, checking for missing data, and visualizing relationships."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1f0c8045-6a6d-4835-96ba-8521a0d00a5c"},{"cell_type":"code","source":["from pyspark.sql.functions import count, isnan, col, mean, corr\n","\n","# Step 1: Check for missing data\n","df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n","\n","# Step 2: Compute summary statistics for numerical columns\n","df.describe().show()\n","\n","# Step 3: Calculate correlation between features and the target variable\n","df.select(corr(\"median_income\", \"median_house_value\").alias(\"corr_income_housevalue\")).show()\n","df.select(corr(\"total_rooms\", \"median_house_value\").alias(\"corr_rooms_housevalue\")).show()\n","\n","# Visualization example (assuming matplotlib is supported for plots)\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","# Convert to Pandas for quick visualizations\n","pandas_df = df.toPandas()\n","\n","# Plotting median income vs house value\n","plt.scatter(pandas_df['median_income'], pandas_df['median_house_value'])\n","plt.xlabel(\"Median Income\")\n","plt.ylabel(\"Median House Value\")\n","plt.title(\"Income vs House Value\")\n","plt.show()\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4b1ab2bf-a016-419f-a3fd-1fc001b98ce7"},{"cell_type":"markdown","source":["## Step 3: Feature Engineering"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6ccabc7a-86eb-44ad-8854-b729f0f52044"},{"cell_type":"markdown","source":["Now, we prepare the dataset for modeling by performing feature engineering, which may include handling missing values, normalizing features, and creating a feature vector."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"eaec2988-3eb5-49c8-9100-2ecee0e57515"},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.sql.functions import when\n","\n","# Step 1: Handle missing values (impute with the mean for simplicity)\n","df = df.fillna(df.agg(*[mean(c).alias(c) for c in df.columns]).first().asDict())\n","\n","# Step 2: Feature Engineering - Assemble all features into a single feature vector\n","assembler = VectorAssembler(\n","    inputCols=[\"median_income\", \"house_age\", \"total_rooms\", \"total_bedrooms\", \"population\"],\n","    outputCol=\"features\"\n",")\n","\n","df_final = assembler.transform(df)\n","\n","# Select features and the target column for modeling\n","df_final = df_final.select(\"features\", \"median_house_value\")\n","df_final.show(5)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"98ede059-81da-492b-ad22-bd26107e32fc"},{"cell_type":"markdown","source":["## Step 4: Build and Train the Model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fb2633ef-c846-414f-98ea-ac58f4be8ae0"},{"cell_type":"markdown","source":["We will now build a Linear Regression model to predict house prices (**median_house_value**) based on the feature vector created in the previous step."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b39d960e-9d1a-4801-a436-c332bdd4453a"},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\n","from pyspark.ml.evaluation import RegressionEvaluator\n","\n","# Step 1: Split the data into training and test sets\n","train_df, test_df = df_final.randomSplit([0.8, 0.2], seed=42)\n","\n","# Step 2: Initialize the Linear Regression model\n","lr = LinearRegression(featuresCol=\"features\", labelCol=\"median_house_value\")\n","\n","# Step 3: Train the model\n","lr_model = lr.fit(train_df)\n","\n","# Step 4: Print model coefficients and intercept\n","print(f\"Coefficients: {lr_model.coefficients}\")\n","print(f\"Intercept: {lr_model.intercept}\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bbf2c136-439a-42aa-97f3-e2a9f36ea951"},{"cell_type":"markdown","source":["## Step 5: Model Evaluation"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"850bbfff-e126-45a6-8d16-04e4c8a82028"},{"cell_type":"markdown","source":["Evaluate the modelâ€™s performance using **Root Mean Squared Error** (RMSE) and R-squared to understand how well it predicts house prices."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8cc8b873-c8d8-407f-b885-51669df12a69"},{"cell_type":"code","source":["# Step 1: Make predictions on the test set\n","predictions = lr_model.transform(test_df)\n","\n","# Step 2: Evaluate the model's performance\n","evaluator = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"rmse\")\n","rmse = evaluator.evaluate(predictions)\n","r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n","\n","print(f\"RMSE: {rmse}\")\n","print(f\"R-Squared: {r2}\")\n","\n","# Step 3: Show sample predictions\n","predictions.select(\"features\", \"median_house_value\", \"prediction\").show(5)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5aaec6dc-b71a-45ff-89ed-78d9df17d50c"},{"cell_type":"markdown","source":["Note!\n","\n","The RMSE is used to measure the error between predicted and actual house prices. The R-squared value explains how much variance is explained by the model.\n","\n","<Finally, sample predictions are displayed to see how the model performed on the test data."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f9c26c3f-7b30-4b22-befa-32722a286cae"},{"cell_type":"markdown","source":["## Step 6: Model Inference and API Implementation"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"494b107e-2667-4059-a2d1-aa76eec58813"},{"cell_type":"markdown","source":["In this step, we implement a simple function to perform inference. This can be integrated into an API or used as part of a pipeline to make predictions on new data."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f4de8534-5ea5-4bb1-a86b-cac5344ee8de"},{"cell_type":"code","source":["def predict_house_price(new_data):\n","    \"\"\"\n","    Function to make predictions on new data.\n","    Input: new_data - A PySpark DataFrame containing the same features as used in training\n","    Output: Predicted house prices\n","    \"\"\"\n","    # Ensure the new data has the same feature columns as training data\n","    assembler = VectorAssembler(\n","        inputCols=[\"median_income\", \"house_age\", \"total_rooms\", \"total_bedrooms\", \"population\"],\n","        outputCol=\"features\"\n","    )\n","    \n","    new_data_transformed = assembler.transform(new_data)\n","    \n","    # Use the trained model to make predictions\n","    predictions = lr_model.transform(new_data_transformed)\n","    \n","    return predictions.select(\"features\", \"prediction\")\n","\n","# Example usage with new data\n","new_data_path = \"Files/Users/DataLake/InferenceData.csv\"\n","new_df = spark.read.csv(new_data_path, header=True, inferSchema=True)\n","predictions = predict_house_price(new_df)\n","predictions.show(5)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"65e4cae6-5453-47a0-8b50-730ba2bef0cb"},{"cell_type":"markdown","source":["You can see the function **predict_house_price** takes new data as input, applies the same feature engineering steps, and uses the trained model to make predictions.\n","\n","This could be wrapped into an API (e.g., using Flask or FastAPI) to provide real-time predictions."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b99e8807-dd6f-492c-b5c8-eb6935a82186"},{"cell_type":"markdown","source":["## Conclusion\n","\n","This end-to-end PySpark notebook demonstrates how to build a machine learning solution in Microsoft Fabric:\n","\n","- Data is loaded from both Data Lake and Lakehouse.\n","- Exploratory Data Analysis (EDA) helps understand the dataset.\n","- A Linear Regression model is built to predict house prices.\n","- The model is evaluated and inference is performed on new data.\n","\n","You can expand this workflow by adding more sophisticated preprocessing, trying different models, or automating the pipeline for real-time data updates and model retraining."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6f2ecf2e-38fa-40ca-a4c5-fdffec6ea744"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"8254f032-6f1c-4f47-ad3a-f1ec5019be2f","default_lakehouse_name":"LK_flights","default_lakehouse_workspace_id":"3db7091c-9d93-489e-930b-f676a1179736"}}},"nbformat":4,"nbformat_minor":5}
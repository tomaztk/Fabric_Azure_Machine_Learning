{"cells":[{"cell_type":"markdown","source":["# Module 5"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b86164df-8439-4146-9650-ab617169c1ac"},{"cell_type":"markdown","source":["### Fabric Prerequistis\n","\n","You need to have Lakehouse enabled and connected. \n","\n","Link to Lakehouse (replace these strings)\n","- Tables: `abfss://Fabric_2024@onelake.dfs.fabric.microsoft.com/LK_flights.Lakehouse/Tables`\n","- Files: `abfss://Fabric_2024@onelake.dfs.fabric.microsoft.com/LK_flights.Lakehouse/Files`\n","\n","You will also need:\n","- PySpark notebook and connect it to the Fabric standard session\n","\n","Data:\n","- Have delta tables created with flights data"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e34ab436-0ab7-444e-bb0a-624424bd0d6b"},{"cell_type":"markdown","source":["## Step 1: Set Up MLFlow in Microsoft Fabric"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"814f70f4-cf36-452f-afb6-5f5e750ab597"},{"cell_type":"markdown","source":["MLFlow will allow us to track, compare, and manage experiments for our machine learning models.\n","\n","Initialize MLFlow in your notebook environment."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8bea34f8-f55d-4584-9408-3e575925d36f"},{"cell_type":"code","source":["import mlflow\n","import mlflow.spark\n","\n","# Set the experiment name for MLFlow tracking\n","mlflow.set_experiment(\"FlightDelayPrediction\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"ms_comments":[{"threadId":"c52ef791-2e7e-4642-9343-84137033fec8","text":"Why?","status":"active","user":{"name":"Tomaž Kaštrun","idType":"aad"},"createdDateUTC":1728239695648,"modifiedDateUTC":1728239695648,"replies":[]}],"ms_comment_ranges":{"c52ef791-2e7e-4642-9343-84137033fec8":{"text":"for MLFlow tracking","start":{"line":4,"column":27},"end":{"line":4,"column":46}}}},"id":"dbf5dbf5-2a9f-474b-866b-33771d06b733"},{"cell_type":"markdown","source":["## Step 2: Load Flight Data from the Lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"667242b2-0923-4c72-91fe-62b9357620db"},{"cell_type":"markdown","source":["We’ll use flight data stored in a Delta table within your Lakehouse. The process of loading the data will remain the same as in previous modules."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4462ca44-1cb7-47b7-bda3-014aec79606b"},{"cell_type":"code","source":["# Step 1: Initialize Spark session\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder.appName(\"FlightDelayPrediction\").getOrCreate()\n","\n","# Step 2: Define the Lakehouse path to the Delta Table\n","lakehouse_table_path = \"abfss://<your-container>@<your-storage-account>.dfs.core.windows.net/delta/flight_data\"\n","\n","# Step 3: Read the flight data from Delta Table in Lakehouse\n","df_flight = spark.read.format(\"delta\").load(lakehouse_table_path)\n","\n","# Step 4: Display the first few rows of the flight data\n","df_flight.show(5)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a356c185-8b7f-4cf1-908b-10c6e444894a"},{"cell_type":"markdown","source":["## Step 3: QUick and simple EDA"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d2d2a0f0-c20c-45af-8d57-20c147fadc58"},{"cell_type":"markdown","source":["Check missing data and calculate"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1741f6d8-e338-492e-ba13-d596e769728e"},{"cell_type":"code","source":["from pyspark.sql.functions import col, count, when\n","\n","# Check for missing data by counting null values in each column\n","missing_data = df_flight.select([count(when(col(c).isNull(), c)).alias(c) for c in df_flight.columns])\n","missing_data.show()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2c07b535-ab5c-4c09-bfbb-a657c5666117"},{"cell_type":"code","source":["df_flight.groupBy(\"is_delay\").count().show()"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bb36ad62-b308-4f4d-ba92-9125c4937db7"},{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"81453cf5-45d8-49a0-84d7-eb8c51ab8ed3"},{"cell_type":"markdown","source":["## Step 4: Data Preparation for the Model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"52646f5c-750a-4c82-bc44-7c9163e41279"},{"cell_type":"markdown","source":["Before building our machine learning model, we need to prepare the data by transforming it into a format suitable for modeling.\n","\n","Index categorical columns and assemble features:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a3f2a983-00c7-4ac4-8f53-8391185ebef4"},{"cell_type":"code","source":["from pyspark.ml.feature import StringIndexer, VectorAssembler\n","\n","# Index categorical columns (e.g., carrier, origin, destination)\n","indexer_carrier = StringIndexer(inputCol=\"carrier\", outputCol=\"carrier_index\")\n","indexer_origin = StringIndexer(inputCol=\"origin\", outputCol=\"origin_index\")\n","indexer_dest = StringIndexer(inputCol=\"destination\", outputCol=\"dest_index\")\n","\n","df_flight = indexer_carrier.fit(df_flight).transform(df_flight)\n","df_flight = indexer_origin.fit(df_flight).transform(df_flight)\n","df_flight = indexer_dest.fit(df_flight).transform(df_flight)\n","\n","# Assemble all features into a single vector column\n","assembler = VectorAssembler(inputCols=[\"carrier_index\", \"origin_index\", \"dest_index\", \"departure_time\"], outputCol=\"features\")\n","df_flight = assembler.transform(df_flight)\n","\n","# Select relevant columns for modeling\n","df_flight = df_flight.select(\"features\", \"is_delay\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ad1d2fae-c66c-4460-a0e2-a94095223122"},{"cell_type":"markdown","source":["## Step 5: Build a Machine Learning Model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bfe299e5-9ba7-4485-a8a1-f64265b424af"},{"cell_type":"markdown","source":["In this step, we’ll build a Logistic Regression model to predict whether a flight will be delayed.\n","\n","Split Data into Training and Test Sets:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4514c863-58a2-4319-9241-a16a354b1caa"},{"cell_type":"code","source":["# Split the data into training (80%) and testing (20%) sets\n","train_df, test_df = df_flight.randomSplit([0.8, 0.2], seed=42)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4b04800c-cd42-4465-902f-946d030113ef"},{"cell_type":"markdown","source":["Define the Logistic Regression Model:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e0c26e86-c143-413d-b912-83a51a865473"},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n","\n","# Initialize Logistic Regression model\n","lr_model = LogisticRegression(featuresCol=\"features\", labelCol=\"is_delay\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e51f20ef-0cbe-4e07-843a-b6c27bc7a0ab"},{"cell_type":"markdown","source":["## Step 6: Run Experiments Using MLFlow"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"947668bd-dda5-4b70-8a5d-bd10dec1c236"},{"cell_type":"markdown","source":["Now, we’ll use MLFlow to log model parameters, track metrics, and save the trained models.\n","\n","Start an MLFlow Experiment:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"13e68632-23a5-49da-897b-2059ea81c672"},{"cell_type":"code","source":["# Start MLFlow run for tracking\n","with mlflow.start_run():\n","    # Train the Logistic Regression model\n","    lr_fitted = lr_model.fit(train_df)\n","    \n","    # Log model parameters\n","    mlflow.log_param(\"model_type\", \"Logistic Regression\")\n","    \n","    # Make predictions on the test data\n","    predictions = lr_fitted.transform(test_df)\n","    \n","    # Log metrics such as AUC (Area Under ROC Curve)\n","    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","    evaluator = BinaryClassificationEvaluator(labelCol=\"is_delay\", metricName=\"areaUnderROC\")\n","    auc = evaluator.evaluate(predictions)\n","    \n","    mlflow.log_metric(\"AUC\", auc)\n","    \n","    # Log the trained model\n","    mlflow.spark.log_model(lr_fitted, \"logistic_regression_model\")\n","    \n","    print(f\"Experiment complete with AUC: {auc}\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a96a56d4-7c41-4910-9d8f-f9a079c2d9d4"},{"cell_type":"markdown","source":["Explanation:\n","\n","* _mlflow.start_run()_ starts an MLFlow run, which is a session to log the parameters, metrics, and models.\n","* _mlflow.log_param()_ logs model parameters like model type.\n","* _mlflow.log_metric()_ tracks metrics like AUC (Area Under the ROC Curve).\n","* _mlflow.spark.log_model()_ saves the trained model into the MLFlow tracking system."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ce460a82-fe82-433e-9084-ba18820791d6"},{"cell_type":"markdown","source":["## Step 7: Compare Models Across Experiments"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dd746f17-71ea-423b-a631-dc87b5e2ea4a"},{"cell_type":"markdown","source":["MLFlow automatically keeps track of all your experiments, so you can compare multiple models to find the best-performing one.\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d2b10935-4525-4143-983b-bc82ad70e0b7"},{"cell_type":"markdown","source":["Track Multiple Experiments:\n","\n","Let’s run another experiment with a Decision Tree Classifier and compare the results with our Logistic Regression model."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4e2aa8c6-da49-4be4-af90-3aa42ae5ba84"},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n","\n","# Initialize the Decision Tree Classifier\n","dt_model = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"is_delay\")\n","\n","# Start a new MLFlow run for the Decision Tree model\n","with mlflow.start_run():\n","    # Train the Decision Tree model\n","    dt_fitted = dt_model.fit(train_df)\n","    \n","    # Log the model type as Decision Tree\n","    mlflow.log_param(\"model_type\", \"Decision Tree\")\n","    \n","    # Make predictions on the test data\n","    predictions = dt_fitted.transform(test_df)\n","    \n","    # Calculate AUC and log the metric\n","    auc = evaluator.evaluate(predictions)\n","    mlflow.log_metric(\"AUC\", auc)\n","    \n","    # Log the trained model\n","    mlflow.spark.log_model(dt_fitted, \"decision_tree_model\")\n","    \n","    print(f\"Experiment complete with AUC: {auc}\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ec0871a3-3f63-47f4-81ee-0c52b8626751"},{"cell_type":"markdown","source":["You can now compare the AUC for both models to determine which one performed better."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"906d2608-0d69-4eb0-9334-5b05e1dbbbc3"},{"cell_type":"markdown","source":["## Step 8: Model Versioning and Productionization"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b601b34e-fda8-4527-8df7-6f47e23274d2"},{"cell_type":"markdown","source":["Once you have identified the best model, you can register it for production, track its versions, and use it in different environments (test, dev, prod)."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0ae4cb48-1ab9-48b6-935d-ee090855e445"},{"cell_type":"markdown","source":["1) Register the Model in MLFlow for versioning and deployment."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d6fc28da-5c74-4117-a8bc-b70cc4b25706"},{"cell_type":"code","source":["# Register the Logistic Regression model as a versioned model in MLFlow\n","mlflow.register_model(\"runs:/<run-id>/logistic_regression_model\", \"FlightDelayPredictionModel\")"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e0c1af77-184e-4f08-ac76-17343e150b15"},{"cell_type":"markdown","source":["2) Promote the Best Model:\n","\n","Use MLFlow to promote the best model to the production environment. This helps in managing models across test, dev, and prod environments."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5473e9fa-10ae-41bf-ad6d-59851aea7408"},{"cell_type":"markdown","source":["## Step 9: Inference and Predictions Using the Trained Model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1cf36ca6-a961-4b09-9145-e880d19f52e3"},{"cell_type":"markdown","source":["Once your model is registered in MLFlow, you can load it for inference and make predictions on new flight data.\n","\n","1) Load the Registered Model for Inference:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0a23b111-9317-4f64-9a36-02f4def80050"},{"cell_type":"code","source":["# Load the model from MLFlow for inference\n","import mlflow.pyfunc\n","\n","# Load model version from MLFlow model registry\n","model_uri = \"models:/FlightDelayPredictionModel/production\"\n","loaded_model = mlflow.pyfunc.load_model(model_uri)\n","\n","# Example: Predict delay for a new flight\n","new_flight_data = spark.createDataFrame([\n","    (\"AA\", \"LAX\", \"JFK\", \"16:00\")\n","], [\"carrier\", \"origin\", \"destination\", \"departure_time\"])\n","\n","# Transform data to fit the model's input requirements\n","new_flight_data = indexer_carrier.fit(new_flight_data).transform(new_flight_data)\n","new_flight_data = indexer_origin.fit(new_flight_data).transform(new_flight_data)\n","new_flight_data = indexer_dest.fit(new_flight_data).transform(new_flight_data)\n","new_flight_data = assembler.transform(new_flight_data)\n","\n","# Predict using the loaded model\n","new_flight_predictions = loaded_model.predict(new_flight_data)\n","new_flight_predictions.show()\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"abe16866-ad3c-4ecd-8f90-38939e40961d"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"8254f032-6f1c-4f47-ad3a-f1ec5019be2f","default_lakehouse_name":"LK_flights","default_lakehouse_workspace_id":"3db7091c-9d93-489e-930b-f676a1179736"}}},"nbformat":4,"nbformat_minor":5}